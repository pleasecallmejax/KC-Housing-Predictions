{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kings County Housing Prices Bakeoff\n",
    "\n",
    "Below are a list of steps that you should take while trying to complete your bake-off entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import folium\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy.stats as stats\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2591820310</th>\n",
       "      <td>20141006T000000</td>\n",
       "      <td>365000.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2070</td>\n",
       "      <td>8893</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>98058</td>\n",
       "      <td>47.44</td>\n",
       "      <td>-122.16</td>\n",
       "      <td>2390</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974200820</th>\n",
       "      <td>20140821T000000</td>\n",
       "      <td>865000.00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2900</td>\n",
       "      <td>6730</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1830</td>\n",
       "      <td>1070</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.68</td>\n",
       "      <td>-122.28</td>\n",
       "      <td>2370</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701450110</th>\n",
       "      <td>20140815T000000</td>\n",
       "      <td>1038000.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3770</td>\n",
       "      <td>10893</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3770</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.56</td>\n",
       "      <td>-122.13</td>\n",
       "      <td>3710</td>\n",
       "      <td>9685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9522300010</th>\n",
       "      <td>20150331T000000</td>\n",
       "      <td>1490000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4560</td>\n",
       "      <td>14608</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4560</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.70</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4050</td>\n",
       "      <td>14226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510861140</th>\n",
       "      <td>20140714T000000</td>\n",
       "      <td>711000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2550</td>\n",
       "      <td>5376</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2550</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.66</td>\n",
       "      <td>-122.08</td>\n",
       "      <td>2250</td>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "id                                                                         \n",
       "2591820310  20141006T000000  365000.00         4       2.25         2070   \n",
       "7974200820  20140821T000000  865000.00         5       3.00         2900   \n",
       "7701450110  20140815T000000 1038000.00         4       2.50         3770   \n",
       "9522300010  20150331T000000 1490000.00         3       3.50         4560   \n",
       "9510861140  20140714T000000  711000.00         3       2.50         2550   \n",
       "\n",
       "            sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "id                                                                             \n",
       "2591820310      8893    2.00           0     0          4      8        2070   \n",
       "7974200820      6730    1.00           0     0          5      8        1830   \n",
       "7701450110     10893    2.00           0     2          3     11        3770   \n",
       "9522300010     14608    2.00           0     2          3     12        4560   \n",
       "9510861140      5376    2.00           0     0          3      9        2550   \n",
       "\n",
       "            sqft_basement  yr_built  yr_renovated  zipcode   lat    long  \\\n",
       "id                                                                         \n",
       "2591820310              0      1986             0    98058 47.44 -122.16   \n",
       "7974200820           1070      1977             0    98115 47.68 -122.28   \n",
       "7701450110              0      1997             0    98006 47.56 -122.13   \n",
       "9522300010              0      1990             0    98034 47.70 -122.23   \n",
       "9510861140              0      2004             0    98052 47.66 -122.08   \n",
       "\n",
       "            sqft_living15  sqft_lot15  \n",
       "id                                     \n",
       "2591820310           2390        7700  \n",
       "7974200820           2370        6283  \n",
       "7701450110           3710        9685  \n",
       "9522300010           4050       14226  \n",
       "9510861140           2250        4050  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_hous_df=pd.read_csv('Data/kc_house_data_train.csv', index_col='id').drop('Unnamed: 0', axis=1)\n",
    "org_hous_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zipcode\n",
      "98039   2202790.00\n",
      "98004   1396882.89\n",
      "98040   1183018.00\n",
      "98112   1119457.66\n",
      "98102    933671.47\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top5codes_price = org_hous_df.groupby(\"zipcode\")[\"price\"].mean().sort_values(ascending = False)[:5]\n",
    "mean_price = org_hous_df.price.mean()\n",
    "print(top5codes_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zipcode\n",
       "98052    474\n",
       "98115    465\n",
       "98103    461\n",
       "98038    455\n",
       "98117    437\n",
       "        ... \n",
       "98102     80\n",
       "98010     74\n",
       "98024     65\n",
       "98148     43\n",
       "98039     42\n",
       "Name: price, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_by_zip = org_hous_df.groupby(\"zipcode\")[\"price\"].count().sort_values(ascending = False)[:70]\n",
    "count_by_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98039</th>\n",
       "      <td>2202790.00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98004</th>\n",
       "      <td>1396882.89</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98040</th>\n",
       "      <td>1183018.00</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98112</th>\n",
       "      <td>1119457.66</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98102</th>\n",
       "      <td>933671.47</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98001</th>\n",
       "      <td>281998.76</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98148</th>\n",
       "      <td>272082.33</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98032</th>\n",
       "      <td>251602.23</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98168</th>\n",
       "      <td>241041.54</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98002</th>\n",
       "      <td>232286.53</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             price  count\n",
       "zipcode                  \n",
       "98039   2202790.00     42\n",
       "98004   1396882.89    237\n",
       "98040   1183018.00    229\n",
       "98112   1119457.66    216\n",
       "98102    933671.47     80\n",
       "...            ...    ...\n",
       "98001    281998.76    284\n",
       "98148    272082.33     43\n",
       "98032    251602.23    103\n",
       "98168    241041.54    215\n",
       "98002    232286.53    157\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_price_by_zip = org_hous_df.groupby(\"zipcode\")[\"price\"].mean().sort_values(ascending = False)[:70]\n",
    "mean_price_by_zip = mean_price_by_zip.to_frame()\n",
    "mean_price_by_zip['count'] = count_by_zip\n",
    "mean_price_by_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6824544554785027"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_bedrooms = org_hous_df[org_hous_df['bedrooms'] == 0]['price']\n",
    "no_bathrooms = org_hous_df[org_hous_df['bathrooms'] == 0]['price']\n",
    "bathroom_pvalue = stats.ttest_ind(no_bedrooms, no_bathrooms)[1]\n",
    "bathroom_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.float64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a372c99aea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is more than alpha, accept null-hypothesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstattest_hypo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbathroom_pvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-a372c99aea28>\u001b[0m in \u001b[0;36mstattest_hypo\u001b[0;34m(pvalue)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is less than alpha, reject null-hypothesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is more than alpha, accept null-hypothesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstattest_hypo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbathroom_pvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.float64\") to str"
     ]
    }
   ],
   "source": [
    "alpha=.05\n",
    "\n",
    "def stattest_hypo(pvalue):\n",
    "    if pvalue < alpha:\n",
    "        print(\"The \"+ pvalue + \" is less than alpha, reject null-hypothesis\")\n",
    "    else:\n",
    "        print(\"The \"+ pvalue + \" is more than alpha, accept null-hypothesis\")\n",
    "        \n",
    "stattest_hypo(bathroom_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c3e86224257f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmulti_p_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Multiple Floor vs. Single Floor T-test P Value: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_p_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_p_val\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The P value is less than alpha, reject null-hypothesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multi' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "multi_p_val = stats.ttest_ind(multi.price, single.price, equal_var=False)[1]\n",
    "print(\"Multiple Floor vs. Single Floor T-test P Value: \", multi_p_val)\n",
    "if multi_p_val < alpha:\n",
    "    print(\"The P value is less than alpha, reject null-hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis \n",
    "    \n",
    "Become familiar with the data.  Look to see if there are any extreme values.  \n",
    "\n",
    "Additionally create data visualizations to determine if there are any relationships between your features and your target variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_hous_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify colinearity for all features with price with plots\n",
    "fig, axes = plt.subplots(6, 3, figsize=(20,30), sharey=True)\n",
    "for ax, column in zip(axes.flatten(), org_hous_df.columns[2:]):\n",
    "    ax.scatter(org_hous_df[column], org_hous_df['price'], label=column, alpha=.05)\n",
    "    ax.set_title(f'Price vs {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_hous_df.groupby(\"view\")[\"price\"].mean().plot(kind='bar', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = org_hous_df.corr().abs()\n",
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "sns.heatmap(corr[:20], xticklabels=corr[:20].columns, \\\n",
    "            yticklabels=corr[:20].columns, \\\n",
    "            annot=False, cmap='Blues_r', center= 0)\n",
    "plt.title('Degrees of Correlation in dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('Blues_r')\n",
    "x = ['98039', '98004', '98040', '98112', '98102']\n",
    "y = [2.202790e+06, 1.396883e+06, 1.183018e+06, 1.119458e+06, 9.336715e+05]\n",
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "ax = sns.barplot(x=x,y=y, data=org_hous_df)\n",
    "ax.ticklabel_format(style='scientific', axis='y')\n",
    "\n",
    "ax.set(xlabel='Zip Code', ylabel='Avg. Price')\n",
    "plt.title(\"Average Home Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "sns.distplot(org_hous_df['price'], bins=50, color = 'b')\n",
    "ax.set(xlim=[0, 5000000], xlabel='Sale Price', ylabel='Sale Count',\n",
    "       title='Sale Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='ticks', palette=\"rocket\")\n",
    "org_hous_df.hist(bins=50, figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'waterfront'\n",
    "data = pd.concat([org_hous_df['price'], org_hous_df[var]], axis=1)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "fig = sns.boxplot(x=var, y='price', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'grade'\n",
    "data = pd.concat([org_hous_df['grade'], org_hous_df[var]], axis=1)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "fig = sns.boxplot(x=var, y='price', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = org_hous_df, x = org_hous_df['price'], y = org_hous_df['sqft_living'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folium Map using coordinates\n",
    "kc_map = folium.Map(location = [47.5480, -121.9836], tiles = 'OpenStreetMap', zoom_start = 9)\n",
    "\n",
    "kc_coord = list(zip(org_hous_df['lat'], org_hous_df['long']))\n",
    "\n",
    "for coord in kc_coord:\n",
    "    folium.Marker(location = coord).add_to(kc_map)\n",
    "\n",
    "#kc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean up any issues (extreme values, etc.) with the data.  \n",
    "\n",
    "Remember that you can't just delete rows with extreme values. Similar observations might be present in the holdout data set, and you can't just delete those rows and not have a prediction for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrooms - 33 bedroom house on Google Maps seems to be typo for a 3 bedroom house, twelve \"studios\" with no bedrooms\n",
    "bathrooms - eight with no bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct 33 bedroom home\n",
    "org_hous_df['bedrooms'].replace(33, 3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned df\n",
    "org_hous_df.to_csv('~/Data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate new features that you think could be important.\n",
    "\n",
    "After doing this, you will want to go back to steps 2 and 3 to investigate these new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yard_space column\n",
    "org_hous_df['yard_space'] = org_hous_df.sqft_lot - (org_hous_df.sqft_living / org_hous_df.floors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi_floor_column\n",
    "org_hous_df['multi_floor'] = [0 if x == 1 else 1 for x in org_hous_df.floors] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basement coulumn\n",
    "org_hous_df['has_basement'] = [0 if x == 0 else 1 for x in org_hous_df.sqft_basement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sale_month column to explore affeect of seasons\n",
    "org_hous_df['sale_month'] = pd.DatetimeIndex(org_hous_df['date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year Renovated coulumn\n",
    "org_hous_df['yr_built_reno'] = np.where((org_hous_df['yr_built'] < 1974) & (org_hous_df['yr_renovated'] == 0), 0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Identify a categorical variable in the data set and create dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identified zipcode,grade and view\n",
    "#org_hous_df=pd.get_dummies(org_hous_df, columns=['zipcode'], drop_first=True)\n",
    "#org_hous_df=pd.get_dummies(org_hous_df, columns=['grade'], drop_first=True)\n",
    "#org_hous_df=pd.get_dummies(org_hous_df, columns=['view'], drop_first=True)\n",
    "org_hous_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) There are columns for when the house was built and when it was renovated.  How could you use these columns to create a new column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols(formula='price~sqft_living', data= org_hous_df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Non-linear transformations</ins>\n",
    "\n",
    "### 4.4) Create a polynomial feature for two of your continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#org_hous_df['sqft_living^3'] = org_hous_df['sqft_living']**3\n",
    "#org_hous_df['sqft_living^2'] = org_hous_df['sqft_living']**2\n",
    "#org_hous_df['sqft_basement^2'] = org_hous_df['sqft_basement']**2\n",
    "org_hous_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Create an interaction feature between a binary variable (dummy variable) and a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqft of homes sold with the best view\n",
    "#org_hous_df['bestview_sqftliving'] = org_hous_df['view_4']*org_hous_df['sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipcode with 474 houses sqft\n",
    "#org_hous_df['biggestzipcode_sqftliving'] = org_hous_df['zipcode_98052']*org_hous_df['sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['sqft_living','sqft_lot','sqft_above','sqft_basement','yr_built','sqft_living15','sqft_lot15']\n",
    "\n",
    "for column in continuous:\n",
    "    sns.jointplot(x=column, y=\"price\", data=org_hous_df, kind='reg', label=column,joint_kws={'line_kws':{'color':'red'}})\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6) SKLearn Identifying Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['second_sale', 'zipcode_98004', 'zipcode_98038', 'zipcode_98116','zipcode_98117','zipcode_98052',/\n",
    "            'sale_month', 'yard_space', 'grade_3','grade_4','grade_5','grade_6','grade_7','grade_8','grade_9',/\n",
    "            'grade_10','grade_11','grade_12','grade_13','view_1','view_2','view_3', 'view_4', 'sqft_living^2',/\n",
    "            'been_renovated', 'sqft_living^3','sqft_basement^2', 'bestview_sqftliving', 'biggestzipcode_sqftliving']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = org_hous_df.filter(org_hous_df.columns, axis=1)\n",
    "df_features.drop(columns=['lat','long','date', 'id','price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop( 'long', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop( 'date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop( 'id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop( 'price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = org_hous_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#instantiate a linear regression object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(df_features, target)\n",
    "\n",
    "#access output\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)\n",
    "print(\"R^2: \", lm.score(df_features, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_data = poly.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.isnull().value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1)  Fit an initial model and check the errors to see if the model assumptions are being met. If need be, go back to steps 3 and 4 to improve your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols(formula='price~C(zipcode)+sqft_living+view', data= df_features).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_columns = poly.get_feature_names(df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poly_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly = pd.DataFrame(poly_data, columns=poly_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly3_data = poly_3.fit_transform(df_features)\n",
    "poly3_columns = poly_3.get_feature_names(df_features.columns)\n",
    "df_poly3 = pd.DataFrame(poly3_data, columns=poly3_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_2 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_2 = lm_2.fit(df_poly, target)\n",
    "\n",
    "#access output\n",
    "print(lm_2.intercept_)\n",
    "print(lm_2.coef_)\n",
    "print(\"R^2: \", lm_2.score(df_poly, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_3 = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_3 = lm_3.fit(df_poly3, target)\n",
    "\n",
    "#access output\n",
    "# print(lm_3.intercept_)\n",
    "# print(lm_3.coef_)\n",
    "print(\"R^2: \", lm_3.score(df_poly3, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Perform a train-test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, random_state=9,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, target, test_size=0.3, random_state=34)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#transform the training data\n",
    "scaled_data = scaler.transform(X_train)\n",
    "\n",
    "#create dataframe\n",
    "X_train = pd.DataFrame(data=scaled_data, columns=df_features.columns)\n",
    "\n",
    "#transform the testing dat\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=df_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Use the model to predict on the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the results\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape)\n",
    "print(\"Training set - Features: \", X_test.shape, \"Target: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5) Evaluate the training and test predictions using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6) Determine if your model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(df_features, target):\n",
    "    testtrainsplit\n",
    "    lm = LinearRegression()\n",
    "    lm.fit()\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_rmse = test_data(org_hous_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Utilize some different feature selection techniques before or in conjuction with fitting your models. You will have to repeat steps 5.3 through 5.6 to determine how your new model is performing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Utilize a filter method to identify some features to remove from the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k='all')\n",
    "\n",
    "selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train.columns[selector.get_support()]\n",
    "removed_columns = X_train.columns[~selector.get_support()]\n",
    "X_train = X_train[selected_columns]\n",
    "X_test = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2) After removing the features, re-run Step 5 and see if your new model performs better than the old model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a linear regression object\n",
    "lm_kbest = LinearRegression()\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm_kbest.fit(df_features, target)\n",
    "\n",
    "y_train_kbest = lm_kbest.predict(df_features)\n",
    "\n",
    "\n",
    "trainK_rmse = np.sqrt(metrics.mean_squared_error(y_train, y_train_kbest))\n",
    "\n",
    "\n",
    "print('Training Root Mean Squared Error:' , trainK_rmse)\n",
    "\n",
    "y_kbest = lm_kbest.predict(X_test)\n",
    "\n",
    "testK_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_kbest))\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , testK_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"model.pickle\",\"wb\")\n",
    "\n",
    "pickle.dump(lm, pickle_out)\n",
    "\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"column_selection.pickle\",\"wb\")\n",
    "\n",
    "pickle.dump(df_features.columns, pickle_out)\n",
    "\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare the RMSE of your different models that use different features and determine the best model overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8:  Refit your best model to the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save your final model using pickle.\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
